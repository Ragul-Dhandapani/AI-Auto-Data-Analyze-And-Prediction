"""
Enhanced Chat Service with Azure OpenAI
Full-featured AI data analysis assistant with:
- Dataset awareness
- Chart creation/manipulation
- Prediction insights
- Interactive workflows
- Analytical guidance
"""
import logging
import json
from typing import Dict, Any, List, Optional
import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


class EnhancedChatService:
    """AI-powered chat assistant for data analysis"""
    
    def __init__(self):
        self.context = {}
        
    async def process_message(
        self,
        message: str,
        dataset_id: str,
        dataset: Optional[pd.DataFrame] = None,
        analysis_results: Optional[Dict] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        Process user message with full context awareness
        
        Args:
            message: User's chat message
            dataset_id: Current dataset ID
            dataset: DataFrame (if available)
            analysis_results: ML model results (if available)
            conversation_history: Previous messages
            
        Returns:
            {
                'response': str,
                'action': str,  # 'message', 'chart', 'confirm', 'error'
                'data': dict,  # Additional data (chart config, stats, etc.)
                'requires_confirmation': bool,
                'suggestions': List[str]  # Follow-up suggestions
            }
        """
        try:
            message_lower = message.lower().strip()
            
            # Update context
            self.context = {
                'dataset_id': dataset_id,
                'has_dataset': dataset is not None,
                'has_results': analysis_results is not None,
                'dataset_shape': dataset.shape if dataset is not None else None,
                'columns': list(dataset.columns) if dataset is not None else [],
                'analysis_results': analysis_results
            }
            
            # Route to appropriate handler
            if dataset is None or (isinstance(dataset, pd.DataFrame) and dataset.empty):
                return await self._handle_no_dataset()
            
            # 1. Dataset Information Requests
            if any(keyword in message_lower for keyword in ['columns', 'column names', 'what columns', 'available columns']):
                return await self._handle_column_list(dataset)
            
            if any(keyword in message_lower for keyword in ['dataset size', 'how many rows', 'shape', 'dimensions']):
                return await self._handle_dataset_info(dataset)
            
            if 'statistics' in message_lower or 'stats' in message_lower or 'summary' in message_lower:
                return await self._handle_statistics(dataset, message)
            
            if 'data type' in message_lower or 'dtype' in message_lower:
                return await self._handle_dtypes(dataset)
            
            if 'null' in message_lower or 'missing' in message_lower:
                return await self._handle_missing_values(dataset)
            
            if 'correlation' in message_lower:
                return await self._handle_correlation(dataset, message)
            
            # 2. Chart Creation Commands
            if any(keyword in message_lower for keyword in ['create chart', 'plot', 'visualize', 'show chart', 'draw']):
                return await self._handle_chart_creation(dataset, message, analysis_results)
            
            # 3. Model/Prediction Insights
            if analysis_results:
                if any(keyword in message_lower for keyword in ['prediction target', 'target variable', 'what am i predicting']):
                    return await self._handle_target_info(analysis_results)
                
                if any(keyword in message_lower for keyword in ['metrics', 'accuracy', 'performance', 'r2', 'rmse']):
                    return await self._handle_metrics(analysis_results)
                
                if any(keyword in message_lower for keyword in ['best model', 'top model', 'which model']):
                    return await self._handle_best_model(analysis_results)
                
                if 'feature importance' in message_lower or 'important features' in message_lower:
                    return await self._handle_feature_importance(analysis_results)
                
                if 'compare model' in message_lower:
                    return await self._handle_model_comparison(analysis_results)
            
            # 4. Analytical Assistance
            if 'anomaly' in message_lower or 'outlier' in message_lower:
                return await self._handle_anomaly_detection(dataset, message)
            
            if 'trend' in message_lower:
                return await self._handle_trend_analysis(dataset, message)
            
            if any(keyword in message_lower for keyword in ['what does this mean', 'interpret', 'explain']):
                return await self._handle_interpretation(dataset, analysis_results, message)
            
            if 'what next' in message_lower or 'suggestion' in message_lower or 'recommend' in message_lower:
                return await self._handle_suggestions(dataset, analysis_results)
            
            # 5. General Query - Use Azure OpenAI
            return await self._handle_general_query(message, dataset, analysis_results, conversation_history)
            
        except Exception as e:
            logger.error(f"Chat processing error: {str(e)}", exc_info=True)
            return {
                'response': f"I encountered an error processing your request: {str(e)}",
                'action': 'error',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Try rephrasing your question', 'Ask about dataset columns', 'Request statistics']
            }
    
    async def _handle_no_dataset(self) -> Dict:
        """Handle chat when no dataset is loaded"""
        return {
            'response': "‚ö†Ô∏è No dataset is currently loaded. Please upload or select a dataset first to start analysis.",
            'action': 'message',
            'data': {},
            'requires_confirmation': False,
            'suggestions': [
                'Upload a CSV file',
                'Connect to a database',
                'Select an existing dataset'
            ]
        }
    
    async def _handle_column_list(self, dataset: pd.DataFrame) -> Dict:
        """List all available columns"""
        columns = list(dataset.columns)
        numeric_cols = dataset.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = dataset.select_dtypes(include=['object', 'category']).columns.tolist()
        
        response = f"üìä **Dataset Columns ({len(columns)} total)**\n\n"
        response += f"**Numeric columns ({len(numeric_cols)}):**\n{', '.join(numeric_cols[:15])}"
        if len(numeric_cols) > 15:
            response += f" ... and {len(numeric_cols) - 15} more"
        
        response += f"\n\n**Categorical columns ({len(categorical_cols)}):**\n{', '.join(categorical_cols[:10])}"
        if len(categorical_cols) > 10:
            response += f" ... and {len(categorical_cols) - 10} more"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'columns': columns, 'numeric': numeric_cols, 'categorical': categorical_cols},
            'requires_confirmation': False,
            'suggestions': [
                f'Show statistics for {columns[0]}',
                'Check for missing values',
                f'Create a chart for {numeric_cols[0] if numeric_cols else columns[0]}'
            ]
        }
    
    async def _handle_dataset_info(self, dataset: pd.DataFrame) -> Dict:
        """Provide dataset size and shape info"""
        rows, cols = dataset.shape
        memory_mb = dataset.memory_usage(deep=True).sum() / 1024 / 1024
        
        response = f"üìà **Dataset Information**\n\n"
        response += f"‚Ä¢ **Rows:** {rows:,}\n"
        response += f"‚Ä¢ **Columns:** {cols}\n"
        response += f"‚Ä¢ **Memory Usage:** {memory_mb:.2f} MB\n"
        response += f"‚Ä¢ **Data Density:** {(1 - dataset.isnull().sum().sum() / (rows * cols)) * 100:.1f}% complete"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'rows': rows, 'columns': cols, 'memory_mb': memory_mb},
            'requires_confirmation': False,
            'suggestions': [
                'Show column names',
                'Check for missing values',
                'Show summary statistics'
            ]
        }
    
    async def _handle_statistics(self, dataset: pd.DataFrame, message: str) -> Dict:
        """Provide statistical summary"""
        # Check if specific column mentioned
        columns = list(dataset.columns)
        target_col = None
        
        # Try to find mentioned column name in message
        for col in columns:
            # Exact match (case-insensitive)
            if col.lower() in message.lower():
                target_col = col
                break
            # Match with spaces instead of underscores
            col_spaced = col.lower().replace('_', ' ')
            if col_spaced in message.lower():
                target_col = col
                break
        
        if target_col and target_col in dataset.select_dtypes(include=[np.number]).columns:
            # Stats for specific column
            col_data = dataset[target_col]
            stats = {
                'mean': col_data.mean(),
                'std': col_data.std(),
                'min': col_data.min(),
                'max': col_data.max(),
                'median': col_data.median(),
                'null_pct': (col_data.isnull().sum() / len(col_data)) * 100
            }
            
            response = f"üìä **Statistics for '{target_col}'**\n\n"
            response += f"‚Ä¢ **Mean:** {stats['mean']:.2f}\n"
            response += f"‚Ä¢ **Std Dev:** {stats['std']:.2f}\n"
            response += f"‚Ä¢ **Min:** {stats['min']:.2f}\n"
            response += f"‚Ä¢ **Max:** {stats['max']:.2f}\n"
            response += f"‚Ä¢ **Median:** {stats['median']:.2f}\n"
            response += f"‚Ä¢ **Missing:** {stats['null_pct']:.1f}%"
            
            return {
                'response': response,
                'action': 'message',
                'data': {'column': target_col, 'stats': stats},
                'requires_confirmation': False,
                'suggestions': [
                    f'Create histogram for {target_col}',
                    f'Check correlation with {target_col}',
                    'Show outliers'
                ]
            }
        else:
            # General statistics
            numeric_cols = dataset.select_dtypes(include=[np.number]).columns
            response = f"üìä **Dataset Statistics Summary**\n\n"
            response += f"**Numeric Columns:** {len(numeric_cols)}\n\n"
            
            for col in numeric_cols[:5]:
                mean_val = dataset[col].mean()
                response += f"‚Ä¢ **{col}:** Mean = {mean_val:.2f}, Std = {dataset[col].std():.2f}\n"
            
            if len(numeric_cols) > 5:
                response += f"\n_...and {len(numeric_cols) - 5} more columns_"
            
            return {
                'response': response,
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': [
                    'Show correlation matrix',
                    'Check for outliers',
                    'Create visualizations'
                ]
            }
    
    async def _handle_dtypes(self, dataset: pd.DataFrame) -> Dict:
        """Show data types for all columns"""
        dtypes_dict = dataset.dtypes.astype(str).to_dict()
        
        # Group by type
        type_groups = {}
        for col, dtype in dtypes_dict.items():
            if dtype not in type_groups:
                type_groups[dtype] = []
            type_groups[dtype].append(col)
        
        response = f"üî§ **Column Data Types**\n\n"
        for dtype, cols in type_groups.items():
            response += f"**{dtype}** ({len(cols)} columns):\n"
            response += f"{', '.join(cols[:10])}\n"
            if len(cols) > 10:
                response += f"_...and {len(cols) - 10} more_\n"
            response += "\n"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'dtypes': dtypes_dict},
            'requires_confirmation': False,
            'suggestions': [
                'Show numeric columns only',
                'Check for categorical columns',
                'Show statistics'
            ]
        }
    
    async def _handle_missing_values(self, dataset: pd.DataFrame) -> Dict:
        """Analyze missing values"""
        missing = dataset.isnull().sum()
        missing_pct = (missing / len(dataset)) * 100
        cols_with_missing = missing[missing > 0].sort_values(ascending=False)
        
        if len(cols_with_missing) == 0:
            response = "‚úÖ Great news! No missing values found in the dataset."
        else:
            response = f"‚ö†Ô∏è **Missing Values Analysis**\n\n"
            response += f"**{len(cols_with_missing)} columns have missing values:**\n\n"
            
            for col in cols_with_missing.head(10).index:
                pct = missing_pct[col]
                count = missing[col]
                status = "üî¥" if pct > 50 else "üü°" if pct > 10 else "üü¢"
                response += f"{status} **{col}:** {count:,} missing ({pct:.1f}%)\n"
            
            if len(cols_with_missing) > 10:
                response += f"\n_...and {len(cols_with_missing) - 10} more columns with missing data_"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'missing_columns': cols_with_missing.to_dict()},
            'requires_confirmation': False,
            'suggestions': [
                'Show columns with < 5% missing',
                'Recommend data cleaning strategy',
                'Visualize missing data patterns'
            ]
        }
    
    async def _handle_correlation(self, dataset: pd.DataFrame, message: str) -> Dict:
        """Calculate and display correlations"""
        numeric_cols = dataset.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) < 2:
            return {
                'response': "‚ùå Need at least 2 numeric columns to calculate correlations.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Show column data types', 'Show dataset info']
            }
        
        # Check if specific column mentioned
        target_col = None
        for col in numeric_cols:
            if col.lower() in message.lower():
                target_col = col
                break
        
        if target_col:
            # Correlation with specific column
            correlations = dataset[numeric_cols].corrwith(dataset[target_col]).sort_values(ascending=False)
            correlations = correlations[correlations.index != target_col]  # Remove self-correlation
            
            response = f"üîó **Correlations with '{target_col}'**\n\n"
            response += "**Top 5 positive correlations:**\n"
            for col, corr in correlations.head(5).items():
                response += f"‚Ä¢ {col}: {corr:.3f}\n"
            
            response += "\n**Top 5 negative correlations:**\n"
            for col, corr in correlations.tail(5).items():
                response += f"‚Ä¢ {col}: {corr:.3f}\n"
        else:
            # General correlation overview
            corr_matrix = dataset[numeric_cols].corr()
            
            # Find strongest correlations (excluding diagonal)
            corr_pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    col1 = corr_matrix.columns[i]
                    col2 = corr_matrix.columns[j]
                    corr_val = corr_matrix.iloc[i, j]
                    corr_pairs.append((col1, col2, corr_val))
            
            corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)
            
            response = f"üîó **Correlation Analysis**\n\n"
            response += "**Strongest correlations:**\n"
            for col1, col2, corr in corr_pairs[:5]:
                response += f"‚Ä¢ {col1} ‚Üî {col2}: {corr:.3f}\n"
        
        return {
            'response': response,
            'action': 'message',
            'data': {},
            'requires_confirmation': False,
            'suggestions': [
                'Create correlation heatmap',
                'Show scatter plot for top correlation',
                'Explain correlation values'
            ]
        }
    
    async def _handle_chart_creation(self, dataset: pd.DataFrame, message: str, analysis_results: Optional[Dict]) -> Dict:
        """Handle chart creation requests with Azure OpenAI intelligence"""
        try:
            # Import required libraries
            try:
                import plotly.express as px
            except ImportError:
                logger.error("Plotly not available")
                return {
                    'response': "‚ùå Chart generation requires Plotly library. Please install it.",
                    'action': 'error',
                    'data': {},
                    'requires_confirmation': False,
                    'suggestions': []
                }
            
            # Parse chart request (uses fallback pattern matching, not Azure OpenAI directly)
            # This avoids potential recursion issues
            chart_config = self._parse_chart_fallback(message, dataset)
            
            if not chart_config:
                return {
                    'response': "‚ùå I couldn't understand the chart request. Please try something like:\n‚Ä¢ 'Create a scatter plot of price vs quantity'\n‚Ä¢ 'Show histogram for revenue'\n‚Ä¢ 'Plot latency over time'",
                    'action': 'message',
                    'data': {},
                    'requires_confirmation': False,
                    'suggestions': [
                        'Show me available columns',
                        'Create a chart for the first numeric column',
                        'Generate visualizations automatically'
                    ]
                }
            
            # Validate columns exist - Enhanced validation
            all_columns = list(dataset.columns)
            missing_cols = []
            
            if chart_config.get('x_col'):
                if chart_config['x_col'] not in all_columns:
                    missing_cols.append(chart_config['x_col'])
            
            if chart_config.get('y_col'):
                if chart_config['y_col'] not in all_columns:
                    missing_cols.append(chart_config['y_col'])
            
            if missing_cols:
                # Show top 15 available columns
                available_display = ', '.join(all_columns[:15])
                if len(all_columns) > 15:
                    available_display += f" ... and {len(all_columns) - 15} more"
                
                return {
                    'response': f"‚ùå **Column(s) not found:** {', '.join(missing_cols)}\n\n**Available columns ({len(all_columns)} total):**\n{available_display}\n\nTip: Use exact column names (case-sensitive) or ask me to 'show all columns'.",
                    'action': 'error',
                    'data': {'available_columns': all_columns, 'missing_columns': missing_cols},
                    'requires_confirmation': False,
                    'suggestions': [
                        'Show all column names',
                        f'Create chart with {all_columns[0] if all_columns else "first column"}',
                        'Check data types'
                    ]
                }
            
            # Generate the chart
            fig = None
            chart_type = chart_config.get('chart_type', 'scatter')
            
            try:
                if chart_type == 'scatter' and chart_config.get('x_col') and chart_config.get('y_col'):
                    fig = px.scatter(dataset, x=chart_config['x_col'], y=chart_config['y_col'],
                                    title=f"{chart_config['y_col']} vs {chart_config['x_col']}")
                
                elif chart_type == 'line' and chart_config.get('x_col') and chart_config.get('y_col'):
                    fig = px.line(dataset, x=chart_config['x_col'], y=chart_config['y_col'],
                                 title=f"{chart_config['y_col']} over {chart_config['x_col']}")
                
                elif chart_type == 'bar' and chart_config.get('x_col') and chart_config.get('y_col'):
                    fig = px.bar(dataset, x=chart_config['x_col'], y=chart_config['y_col'],
                                title=f"{chart_config['y_col']} by {chart_config['x_col']}")
                
                elif chart_type == 'histogram' and chart_config.get('x_col'):
                    fig = px.histogram(dataset, x=chart_config['x_col'],
                                      title=f"Distribution of {chart_config['x_col']}")
                
                elif chart_type == 'box' and chart_config.get('y_col'):
                    fig = px.box(dataset, y=chart_config['y_col'],
                                title=f"Box Plot of {chart_config['y_col']}")
                
                elif chart_type == 'pie' and chart_config.get('x_col'):
                    # Count occurrences for pie chart
                    value_counts = dataset[chart_config['x_col']].value_counts().head(10)
                    fig = px.pie(values=value_counts.values, names=value_counts.index,
                                title=f"Distribution of {chart_config['x_col']}")
                
                else:
                    return {
                        'response': f"‚ùå Unable to create {chart_type} chart with the specified columns.",
                        'action': 'message',
                        'data': {},
                        'requires_confirmation': False,
                        'suggestions': ['Try a different chart type', 'Show available columns']
                    }
                
                if fig:
                    # Convert to plotly JSON format (serialize properly)
                    import json
                    chart_data = json.loads(fig.to_json())
                    
                    # Ask for confirmation to append to dashboard
                    return {
                        'response': f"‚úÖ Created {chart_type} chart successfully!\n\n**Do you want to append this chart to the dashboard?**",
                        'action': 'chart',
                        'data': chart_data,
                        'requires_confirmation': True,
                        'suggestions': [
                            'Yes, append to dashboard',
                            'No, just show it here',
                            'Create another chart'
                        ]
                    }
            
            except Exception as e:
                logger.error(f"Chart generation error: {str(e)}")
                return {
                    'response': f"‚ùå Error creating chart: {str(e)}",
                    'action': 'message',
                    'data': {},
                    'requires_confirmation': False,
                    'suggestions': ['Try simpler chart request', 'Check column names']
                }
                
        except Exception as e:
            logger.error(f"Chart creation handler error: {str(e)}", exc_info=True)
            return {
                'response': f"‚ùå Chart creation failed: {str(e)}",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': []
            }
    
    async def _parse_chart_request_with_ai(self, message: str, dataset: pd.DataFrame, azure_service) -> Optional[Dict]:
        """Use Azure OpenAI to parse natural language chart requests with robust fallback"""
        try:
            columns_list = ', '.join(list(dataset.columns)[:30])
            numeric_cols = ', '.join(dataset.select_dtypes(include=[np.number]).columns.tolist()[:20])
            
            # Try Azure OpenAI first
            if azure_service.is_available():
                try:
                    system_prompt = """You are a data visualization API that ONLY returns JSON. 
You must respond with ONLY a JSON object, absolutely no explanations, no markdown, no code examples.
Your entire response must be parseable as JSON."""
                    
                    prompt = f"""{{
  "task": "parse_chart_request",
  "user_message": "{message}",
  "available_columns": [{columns_list}],
  "numeric_columns": [{numeric_cols}],
  "output_format": {{
    "chart_type": "scatter|line|bar|histogram|box|pie",
    "x_col": "exact_column_name_or_null",
    "y_col": "exact_column_name_or_null"
  }}
}}

Return ONLY the output_format JSON with filled values. Match column names exactly from available_columns."""

                    response = await azure_service.generate_completion(
                        prompt=prompt,
                        max_tokens=150,
                        temperature=0.0,  # Zero temperature for deterministic output
                        system_message=system_prompt,
                        json_mode=True
                    )
                    
                    # Parse JSON response
                    import json
                    
                    # Clean response (remove markdown code blocks if present)
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```'):
                        # Extract JSON from markdown code block
                        import re
                        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', cleaned_response, re.DOTALL)
                        if json_match:
                            cleaned_response = json_match.group(1)
                    
                    # Try to parse as JSON
                    try:
                        chart_config = json.loads(cleaned_response)
                        
                        # Validate the structure
                        if isinstance(chart_config, dict) and 'chart_type' in chart_config:
                            # Ensure values are not null strings
                            if chart_config.get('x_col') == 'null':
                                chart_config['x_col'] = None
                            if chart_config.get('y_col') == 'null':
                                chart_config['y_col'] = None
                            
                            logger.info(f"‚úÖ Azure OpenAI parsed chart: {chart_config}")
                            return chart_config
                        else:
                            logger.warning(f"Invalid chart config structure from AI: {chart_config}")
                            
                    except json.JSONDecodeError as e:
                        logger.warning(f"Failed to parse AI response as JSON: {str(e)[:100]}")
                        logger.debug(f"AI response was: {response[:200]}")
                        
                except Exception as e:
                    logger.warning(f"Azure OpenAI chart parsing failed: {str(e)}")
            
            # Always fallback to pattern matching for reliability
            logger.info("Using pattern matching fallback for chart parsing")
            return self._parse_chart_fallback(message, dataset)
            
        except Exception as e:
            logger.error(f"Chart parsing error: {str(e)}")
            return self._parse_chart_fallback(message, dataset)
    
    def _parse_chart_fallback(self, message: str, dataset: pd.DataFrame) -> Optional[Dict]:
        """Enhanced fallback pattern matching for chart requests"""
        message_lower = message.lower()
        columns = list(dataset.columns)
        numeric_cols = dataset.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = dataset.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # Detect chart type with more patterns
        chart_type = 'scatter'  # default
        
        if any(word in message_lower for word in ['histogram', 'distribution', 'frequency']):
            chart_type = 'histogram'
        elif any(word in message_lower for word in ['line', 'over time', 'trend', 'time series', 'temporal']):
            chart_type = 'line'
        elif any(word in message_lower for word in ['bar chart', 'bar graph', 'bars', 'count by', 'group by']):
            chart_type = 'bar'
        elif any(word in message_lower for word in ['box plot', 'box chart', 'outlier', 'quartile']):
            chart_type = 'box'
        elif any(word in message_lower for word in ['pie chart', 'pie graph', 'proportion', 'percentage breakdown']):
            chart_type = 'pie'
        elif any(word in message_lower for word in ['scatter', 'correlation', 'relationship', 'vs', 'versus', 'against']):
            chart_type = 'scatter'
        
        # Find columns mentioned in message (with fuzzy matching)
        mentioned_cols = []
        
        for col in columns:
            # Try exact match
            if col.lower() in message_lower:
                mentioned_cols.append(col)
                continue
            
            # Try with spaces instead of underscores
            col_spaced = col.lower().replace('_', ' ')
            if col_spaced in message_lower:
                mentioned_cols.append(col)
                continue
            
            # Try without underscores
            col_no_underscore = col.lower().replace('_', '')
            if col_no_underscore in message_lower.replace(' ', ''):
                mentioned_cols.append(col)
                continue
            
            # Try partial match (column name is substring of a word in message)
            words = message_lower.split()
            for word in words:
                if col.lower() in word or word in col.lower():
                    if len(word) > 3 and len(col) > 3:  # Avoid spurious short matches
                        mentioned_cols.append(col)
                        break
        
        # Remove duplicates while preserving order
        mentioned_cols = list(dict.fromkeys(mentioned_cols))
        
        logger.info(f"Pattern matching - Chart type: {chart_type}, Mentioned columns: {mentioned_cols}")
        
        # Assign x_col and y_col based on chart type
        x_col = None
        y_col = None
        
        if chart_type in ['histogram', 'box', 'pie']:
            # Single column charts
            if mentioned_cols:
                # Prefer numeric for histogram/box, any for pie
                if chart_type == 'pie':
                    x_col = mentioned_cols[0]
                else:
                    # Find first numeric column in mentioned
                    for col in mentioned_cols:
                        if col in numeric_cols:
                            x_col = col
                            break
                    if not x_col and mentioned_cols:
                        x_col = mentioned_cols[0]
            else:
                # Default: first numeric column
                if numeric_cols:
                    x_col = numeric_cols[0]
            
            if x_col:
                return {'chart_type': chart_type, 'x_col': x_col, 'y_col': None}
        
        else:
            # Two-column charts (scatter, line, bar)
            if len(mentioned_cols) >= 2:
                x_col = mentioned_cols[0]
                y_col = mentioned_cols[1]
            elif len(mentioned_cols) == 1:
                # One column mentioned, find a suitable pair
                x_col = mentioned_cols[0]
                # For the other column, prefer numeric
                for col in numeric_cols:
                    if col != x_col:
                        y_col = col
                        break
            else:
                # No columns mentioned, use smart defaults
                if len(numeric_cols) >= 2:
                    x_col = numeric_cols[0]
                    y_col = numeric_cols[1]
            
            if x_col and y_col:
                return {'chart_type': chart_type, 'x_col': x_col, 'y_col': y_col}
        
        # Last resort: suggest scatter plot with first two numeric columns
        if len(numeric_cols) >= 2:
            logger.info(f"Using default scatter plot: {numeric_cols[0]} vs {numeric_cols[1]}")
            return {'chart_type': 'scatter', 'x_col': numeric_cols[0], 'y_col': numeric_cols[1]}
        
        # No valid chart configuration found
        logger.warning("Could not parse chart request - no valid configuration found")
        return None
    
    async def _handle_general_query(self, message: str, dataset: Optional[pd.DataFrame], analysis_results: Optional[Dict], conversation_history: Optional[List[Dict]]) -> Dict:
        """Handle general questions using Azure OpenAI"""
        try:
            from app.services.azure_openai_service import get_azure_openai_service
            
            azure_service = get_azure_openai_service()
            
            if not azure_service.is_available():
                return {
                    'response': "I can help with specific data analysis tasks. Try asking about:\n‚Ä¢ Dataset columns\n‚Ä¢ Statistics\n‚Ä¢ Missing values\n‚Ä¢ Correlations\n‚Ä¢ Model performance",
                    'action': 'message',
                    'data': {},
                    'requires_confirmation': False,
                    'suggestions': ['Show columns', 'Check statistics', 'Show missing values']
                }
            
            # Build context
            context = f"User question: {message}\n\n"
            context += f"Dataset context:\n"
            if dataset is not None:
                context += f"- Rows: {len(dataset)}, Columns: {len(dataset.columns)}\n"
                context += f"- Columns: {', '.join(list(dataset.columns)[:20])}\n"
            
            if analysis_results:
                context += f"- ML models trained: {len(analysis_results.get('ml_models', []))}\n"
                context += f"- Problem type: {analysis_results.get('problem_type', 'unknown')}\n"
            
            # Get AI response
            response = await azure_service.generate_completion(
                prompt=context,
                max_tokens=500,
                temperature=0.7
            )
            
            return {
                'response': response,
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': [
                    'Tell me more',
                    'Show me a chart',
                    'What else can I explore?'
                ]
            }
            
        except Exception as e:
            logger.error(f"Azure OpenAI query failed: {str(e)}")
            return {
                'response': "I can help with data analysis. Try asking specific questions like:\n‚Ä¢ 'Show me column names'\n‚Ä¢ 'What's the dataset size?'\n‚Ä¢ 'Check for missing values'",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Show columns', 'Dataset info', 'Statistics']
            }
    
    # Placeholder methods for remaining handlers
    async def _handle_target_info(self, analysis_results: Dict) -> Dict:
        """Show current prediction target"""
        if not analysis_results or not analysis_results.get('ml_models'):
            return {
                'response': "‚ùå **No models have been trained yet.**\n\nTo see prediction targets, please:\n1. Go to the Predictive Analysis tab\n2. Select your target variable\n3. Run the analysis\n\nOnce models are trained, I can show you the prediction target and metrics.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Go to Predictive Analysis', 'Learn about model training']
            }
        
        ml_models = analysis_results.get('ml_models', [])
        
        # Get target from first model
        target = ml_models[0].get('target_column', 'Unknown')
        problem_type = analysis_results.get('problem_type', 'unknown')
        
        response = f"üéØ **Current Prediction Target**\n\n"
        response += f"‚Ä¢ **Target Variable:** {target}\n"
        response += f"‚Ä¢ **Problem Type:** {problem_type.capitalize()}\n"
        response += f"‚Ä¢ **Models Trained:** {len(ml_models)}"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'target': target, 'problem_type': problem_type},
            'requires_confirmation': False,
            'suggestions': [
                'Show model metrics',
                'Which model is best?',
                'Show feature importance'
            ]
        }
    
    async def _handle_metrics(self, analysis_results: Dict) -> Dict:
        """Display model evaluation metrics"""
        if not analysis_results or not analysis_results.get('ml_models'):
            return {
                'response': "‚ùå **No models have been trained yet.**\n\nTo see model performance metrics:\n1. Navigate to Predictive Analysis tab\n2. Select variables and target\n3. Click 'Run Analysis'\n\nI'll show you accuracy, R¬≤, RMSE, and other metrics once models are trained!",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Start training models', 'Select target variable', 'View dataset info']
            }
        
        ml_models = analysis_results.get('ml_models', [])
        
        problem_type = analysis_results.get('problem_type', 'unknown')
        response = f"üìä **Model Performance Metrics**\n\n"
        
        for i, model in enumerate(ml_models[:5], 1):
            model_name = model.get('model_name', 'Unknown')
            response += f"**{i}. {model_name}**"
            if model.get('is_best'):
                response += " üèÜ"
            response += "\n"
            
            if problem_type == 'regression':
                response += f"   ‚Ä¢ R¬≤ Score: {model.get('r2_score', 0):.4f}\n"
                response += f"   ‚Ä¢ RMSE: {model.get('rmse', 0):.2f}\n"
                response += f"   ‚Ä¢ MAE: {model.get('mae', 0):.2f}\n"
            else:
                response += f"   ‚Ä¢ Accuracy: {model.get('accuracy', 0):.4f}\n"
                response += f"   ‚Ä¢ F1 Score: {model.get('f1_score', 0):.4f}\n"
                response += f"   ‚Ä¢ Precision: {model.get('precision', 0):.4f}\n"
            response += "\n"
        
        if len(ml_models) > 5:
            response += f"_...and {len(ml_models) - 5} more models_"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'models': ml_models},
            'requires_confirmation': False,
            'suggestions': [
                'Show best model',
                'Compare top 3 models',
                'Show feature importance'
            ]
        }
    
    async def _handle_best_model(self, analysis_results: Dict) -> Dict:
        """Identify and describe the best performing model"""
        ml_models = analysis_results.get('ml_models', [])
        best_model = next((m for m in ml_models if m.get('is_best')), None)
        
        if not best_model:
            best_model = ml_models[0] if ml_models else None
        
        if not best_model:
            return {
                'response': "‚ùå No models available to compare.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': []
            }
        
        model_name = best_model.get('model_name', 'Unknown')
        problem_type = analysis_results.get('problem_type', 'unknown')
        
        response = f"üèÜ **Best Model: {model_name}**\n\n"
        
        if problem_type == 'regression':
            r2 = best_model.get('r2_score', 0)
            rmse = best_model.get('rmse', 0)
            response += f"‚Ä¢ **R¬≤ Score:** {r2:.4f} (explains {r2*100:.1f}% of variance)\n"
            response += f"‚Ä¢ **RMSE:** {rmse:.2f}\n"
            response += f"‚Ä¢ **MAE:** {best_model.get('mae', 0):.2f}\n"
        else:
            acc = best_model.get('accuracy', 0)
            response += f"‚Ä¢ **Accuracy:** {acc:.4f} ({acc*100:.1f}% correct predictions)\n"
            response += f"‚Ä¢ **F1 Score:** {best_model.get('f1_score', 0):.4f}\n"
            response += f"‚Ä¢ **Precision:** {best_model.get('precision', 0):.4f}\n"
        
        response += f"\nüí° **Why {model_name}?**\n"
        response += f"This model achieved the highest performance among {len(ml_models)} models tested."
        
        return {
            'response': response,
            'action': 'message',
            'data': {'best_model': best_model},
            'requires_confirmation': False,
            'suggestions': [
                'Compare with other models',
                'Show feature importance',
                'Explain this model'
            ]
        }
    
    async def _handle_feature_importance(self, analysis_results: Dict) -> Dict:
        """Show feature importance ranking"""
        feature_importance = analysis_results.get('feature_importance', {})
        
        if not feature_importance:
            return {
                'response': "‚ùå Feature importance data not available for this analysis.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Show model metrics', 'Show best model']
            }
        
        # Sort by importance
        sorted_features = sorted(feature_importance.items(), key=lambda x: abs(x[1]), reverse=True)
        
        response = f"üéØ **Feature Importance Rankings**\n\n"
        response += "Top features driving predictions:\n\n"
        
        for i, (feature, importance) in enumerate(sorted_features[:10], 1):
            bar_length = int(importance * 20)
            bar = "‚ñà" * bar_length
            response += f"{i}. **{feature}**: {importance:.3f} {bar}\n"
        
        if len(sorted_features) > 10:
            response += f"\n_...and {len(sorted_features) - 10} more features_"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'feature_importance': dict(sorted_features)},
            'requires_confirmation': False,
            'suggestions': [
                f'Show correlation with {sorted_features[0][0]}',
                'Create feature importance chart',
                'Explain top features'
            ]
        }
    
    async def _handle_model_comparison(self, analysis_results: Dict) -> Dict:
        """Compare multiple models"""
        ml_models = analysis_results.get('ml_models', [])
        if len(ml_models) < 2:
            return {
                'response': "‚ùå Need at least 2 models to compare. Train more models first.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': []
            }
        
        problem_type = analysis_results.get('problem_type', 'unknown')
        response = f"üìä **Model Comparison**\n\n"
        
        # Sort by performance
        if problem_type == 'regression':
            sorted_models = sorted(ml_models, key=lambda x: x.get('r2_score', 0), reverse=True)
            metric = 'R¬≤ Score'
        else:
            sorted_models = sorted(ml_models, key=lambda x: x.get('accuracy', 0), reverse=True)
            metric = 'Accuracy'
        
        response += f"Ranking by {metric}:\n\n"
        
        for i, model in enumerate(sorted_models[:10], 1):
            name = model.get('model_name', 'Unknown')
            score = model.get('r2_score' if problem_type == 'regression' else 'accuracy', 0)
            
            response += f"{i}. **{name}**: {score:.4f}"
            if i == 1:
                response += " üèÜ"
            response += "\n"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'sorted_models': sorted_models},
            'requires_confirmation': False,
            'suggestions': [
                'Show best model details',
                'Create comparison chart',
                'Show metrics for all models'
            ]
        }
    
    async def _handle_anomaly_detection(self, dataset: pd.DataFrame, message: str) -> Dict:
        """Detect anomalies/outliers in data"""
        numeric_cols = dataset.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) == 0:
            return {
                'response': "‚ùå No numeric columns found for anomaly detection.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': []
            }
        
        # Use IQR method for outlier detection
        outliers_summary = {}
        
        for col in numeric_cols[:10]:  # Limit to first 10 columns
            Q1 = dataset[col].quantile(0.25)
            Q3 = dataset[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = dataset[(dataset[col] < lower_bound) | (dataset[col] > upper_bound)]
            outlier_count = len(outliers)
            outlier_pct = (outlier_count / len(dataset)) * 100
            
            if outlier_count > 0:
                outliers_summary[col] = {
                    'count': outlier_count,
                    'percentage': outlier_pct
                }
        
        response = f"üîç **Anomaly Detection Results**\n\n"
        
        if not outliers_summary:
            response += "‚úÖ No significant outliers detected using IQR method."
        else:
            response += f"Found outliers in {len(outliers_summary)} columns:\n\n"
            
            for col, info in list(outliers_summary.items())[:5]:
                status = "üî¥" if info['percentage'] > 10 else "üü°" if info['percentage'] > 5 else "üü¢"
                response += f"{status} **{col}:** {info['count']:,} outliers ({info['percentage']:.1f}%)\n"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'outliers': outliers_summary},
            'requires_confirmation': False,
            'suggestions': [
                'Visualize outliers',
                'Remove outliers',
                'Show statistics excluding outliers'
            ]
        }
    
    async def _handle_trend_analysis(self, dataset: pd.DataFrame, message: str) -> Dict:
        """Analyze trends over time"""
        # Look for date/time columns
        date_cols = []
        for col in dataset.columns:
            if 'date' in col.lower() or 'time' in col.lower():
                date_cols.append(col)
        
        if not date_cols:
            return {
                'response': "‚ùå No date/time columns found in the dataset. Add a datetime column for trend analysis.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Show column names', 'Check data types']
            }
        
        response = f"üìà **Trend Analysis**\n\n"
        response += f"Found {len(date_cols)} temporal column(s): {', '.join(date_cols)}\n\n"
        response += "üí° To analyze trends:\n"
        response += "‚Ä¢ Use Time Series Analysis tab\n"
        response += "‚Ä¢ Specify target variable for forecasting\n"
        response += "‚Ä¢ Choose Prophet or LSTM method"
        
        return {
            'response': response,
            'action': 'message',
            'data': {'date_columns': date_cols},
            'requires_confirmation': False,
            'suggestions': [
                'Go to Time Series tab',
                'Show me date column values',
                'Create time series chart'
            ]
        }
    
    async def _handle_interpretation(self, dataset: Optional[pd.DataFrame], analysis_results: Optional[Dict], message: str) -> Dict:
        """Interpret results or charts using Azure OpenAI"""
        try:
            from app.services.azure_openai_service import get_azure_openai_service
            
            azure_service = get_azure_openai_service()
            
            if not azure_service.is_available():
                return {
                    'response': "Interpretation requires Azure OpenAI. Please check configuration.",
                    'action': 'message',
                    'data': {},
                    'requires_confirmation': False,
                    'suggestions': []
                }
            
            # Build context
            context = f"User asked for interpretation: {message}\n\n"
            
            if analysis_results:
                ml_models = analysis_results.get('ml_models', [])
                if ml_models:
                    best = next((m for m in ml_models if m.get('is_best')), ml_models[0])
                    context += f"Best model: {best.get('model_name')}\n"
                    context += f"Performance: {best.get('r2_score', best.get('accuracy', 0)):.3f}\n"
            
            context += "\nProvide a clear, business-friendly interpretation in 2-3 sentences."
            
            interpretation = await azure_service.generate_completion(
                prompt=context,
                max_tokens=300,
                temperature=0.7
            )
            
            return {
                'response': f"üí° **Interpretation:**\n\n{interpretation}",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': ['Tell me more', 'What should I do next?']
            }
            
        except Exception as e:
            logger.error(f"Interpretation failed: {str(e)}")
            return {
                'response': "I can help interpret results. Please be more specific about what you'd like me to explain.",
                'action': 'message',
                'data': {},
                'requires_confirmation': False,
                'suggestions': []
            }
    
    async def _handle_suggestions(self, dataset: Optional[pd.DataFrame], analysis_results: Optional[Dict]) -> Dict:
        """Provide smart analytical suggestions"""
        suggestions = []
        
        if dataset is not None:
            # Check data quality
            null_pct = (dataset.isnull().sum().sum() / (len(dataset) * len(dataset.columns))) * 100
            if null_pct > 5:
                suggestions.append("üî¥ Address missing values (data is {:.1f}% incomplete)".format(null_pct))
            
            # Check for numeric columns
            numeric_cols = dataset.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) >= 2:
                suggestions.append("üìä Explore correlations between numeric variables")
            
            # Check for outliers
            suggestions.append("üîç Run anomaly detection to identify outliers")
            
            # Suggest visualizations
            suggestions.append("üìà Create visualizations to understand distributions")
        
        if analysis_results and analysis_results.get('ml_models'):
            suggestions.append("üèÜ Review best performing model")
            suggestions.append("üéØ Analyze feature importance")
            suggestions.append("üìä Compare model performance")
        
        if not analysis_results or not analysis_results.get('ml_models'):
            suggestions.append("üöÄ Train ML models for predictions")
        
        response = f"üí° **Recommended Next Steps:**\n\n"
        response += "\n".join([f"{i+1}. {s}" for i, s in enumerate(suggestions[:5])])
        
        return {
            'response': response,
            'action': 'message',
            'data': {},
            'requires_confirmation': False,
            'suggestions': [s.split(']')[-1].split(')')[0].strip() if ']' in s or ')' in s else s.replace('üî¥ ', '').replace('üìä ', '').replace('üîç ', '')[:50] for s in suggestions[:3]]
        }
